{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enriching IMDb Ratings Data\n",
    "\n",
    "A utility for extracting data from the openMDb project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from urllib import quote_plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratings dataset comes from [the IMDb project](ftp://ftp.fu-berlin.de/pub/misc/movies/database/ratings.list.gz). I extract out the body of the ratings data (starting at line 296 and going to just before the \"REPORT FORMAT\" line at the end of the report) and create a new `.csv` file from this data using Microsoft Excel.\n",
    "\n",
    "I read the data in and clean up the titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  app.launch_new_instance()\n",
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:6: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/ratings.csv',names=['dist','votes','rating','title'],encoding='mbcs')\n",
    "\n",
    "df['year'] = df['title'].str.extract('\\((\\d\\d\\d\\d)\\/*\\w*\\) *\\(*.*\\)*$')\n",
    "df.dropna(inplace=True)\n",
    "df['year'] = df['year'].astype(np.int32)\n",
    "df['shorttitle'] = df['title'].str.extract('(.*) \\(\\d\\d\\d\\d\\/*\\w*\\) *\\(*.*\\)*$')\n",
    "df['shorttitle'] = df['shorttitle'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are many very small films in the dataset, I'm going to focus on films that have at least 5000 votes. That will limit the database to larger, more well-known films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10075\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist</th>\n",
       "      <th>votes</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>shorttitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0000002311</td>\n",
       "      <td>378326</td>\n",
       "      <td>7.7</td>\n",
       "      <td>(500) Days of Summer (2009)</td>\n",
       "      <td>2009</td>\n",
       "      <td>(500) Days of Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0001111000</td>\n",
       "      <td>10556</td>\n",
       "      <td>5.3</td>\n",
       "      <td>(T)Raumschiff Surprise - Periode 1 (2004)</td>\n",
       "      <td>2004</td>\n",
       "      <td>(T)Raumschiff Surprise - Periode 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0000122100</td>\n",
       "      <td>23547</td>\n",
       "      <td>6.5</td>\n",
       "      <td>*batteries not included (1987)</td>\n",
       "      <td>1987</td>\n",
       "      <td>*batteries not included</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0000012211</td>\n",
       "      <td>7486</td>\n",
       "      <td>7.5</td>\n",
       "      <td>...altrimenti ci arrabbiamo! (1974)</td>\n",
       "      <td>1974</td>\n",
       "      <td>...altrimenti ci arrabbiamo!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0000013211</td>\n",
       "      <td>23117</td>\n",
       "      <td>7.4</td>\n",
       "      <td>...and justice for all. (1979)</td>\n",
       "      <td>1979</td>\n",
       "      <td>...and justice for all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dist   votes  rating                                      title  \\\n",
       "92   0000002311  378326     7.7                (500) Days of Summer (2009)   \n",
       "138  0001111000   10556     5.3  (T)Raumschiff Surprise - Periode 1 (2004)   \n",
       "156  0000122100   23547     6.5             *batteries not included (1987)   \n",
       "184  0000012211    7486     7.5        ...altrimenti ci arrabbiamo! (1974)   \n",
       "186  0000013211   23117     7.4             ...and justice for all. (1979)   \n",
       "\n",
       "     year                          shorttitle  \n",
       "92   2009                (500) Days of Summer  \n",
       "138  2004  (T)Raumschiff Surprise - Periode 1  \n",
       "156  1987             *batteries not included  \n",
       "184  1974        ...altrimenti ci arrabbiamo!  \n",
       "186  1979             ...and justice for all.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsub = df[df['votes']>5000]\n",
    "print(len(dfsub))\n",
    "dfsub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to gather additional data (director and genre) from the openMDb project. I first test the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'Plot': u'Apartment block tenants seek the aid of alien mechanical life-forms to save their building from demolition.', u'Rated': u'PG', u'tomatoImage': u'N/A', u'Title': u'*batteries not included', u'Ratings': [{u'Source': u'Internet Movie Database', u'Value': u'6.5/10'}, {u'Source': u'Rotten Tomatoes', u'Value': u'64%'}], u'DVD': u'16 Mar 1999', u'tomatoMeter': u'N/A', u'Writer': u'Mick Garris (story by), Brad Bird (screenplay), Matthew Robbins (screenplay), Brent Maddock (screenplay), S.S. Wilson (screenplay)', u'tomatoUserRating': u'N/A', u'Production': u'Universal Pictures', u'Actors': u'Hume Cronyn, Jessica Tandy, Frank McRae, Elizabeth Pe\\xf1a', u'tomatoFresh': u'N/A', u'Type': u'movie', u'imdbVotes': u'24,533', u'Website': u'N/A', u'tomatoConsensus': u'N/A', u'Poster': u'https://images-na.ssl-images-amazon.com/images/M/MV5BM2JlMDgxOTYtNmI2My00YzY1LWIyZTgtYzY0MjY3Y2RiZmY2L2ltYWdlL2ltYWdlXkEyXkFqcGdeQXVyNTI4MjkwNjA@._V1_SX300.jpg', u'tomatoRotten': u'N/A', u'Director': u'Matthew Robbins', u'Released': u'18 Dec 1987', u'tomatoUserReviews': u'N/A', u'Awards': u'2 wins & 1 nomination.', u'Genre': u'Comedy, Family, Fantasy', u'tomatoUserMeter': u'N/A', u'imdbRating': u'6.5', u'Language': u'English', u'Country': u'USA', u'BoxOffice': u'N/A', u'Runtime': u'106 min', u'tomatoReviews': u'N/A', u'imdbID': u'tt0092494', u'Metascore': u'N/A', u'Response': u'True', u'tomatoURL': u'http://www.rottentomatoes.com/m/batteries_not_included/', u'tomatoRating': u'N/A', u'Year': u'1987'}\n"
     ]
    }
   ],
   "source": [
    "title = '*batteries not included'\n",
    "year = 1987\n",
    "r = requests.get('http://www.omdbapi.com/?t=' + quote_plus(title) + '&y=' +str(year) + '&plot=short&r=json&tomatoes=true')\n",
    "\n",
    "data = r.json()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then write a function that will run through all the titles in my database and gather the additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'Actors', u'Awards', u'BoxOffice', u'Country', u'DVD', u'Director',\n",
       "       u'Genre', u'Language', u'Metascore', u'Plot', u'Poster',\n",
       "       u'Production', u'Rated', u'Ratings', u'Released', u'Response',\n",
       "       u'Runtime', u'Title', u'Type', u'Website', u'Writer', u'Year',\n",
       "       u'imdbID', u'imdbRating', u'imdbVotes', u'tomatoConsensus',\n",
       "       u'tomatoFresh', u'tomatoImage', u'tomatoMeter', u'tomatoRating',\n",
       "       u'tomatoReviews', u'tomatoRotten', u'tomatoURL', u'tomatoUserMeter',\n",
       "       u'tomatoUserRating', u'tomatoUserReviews'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getJSON(dfrow):\n",
    "    import requests\n",
    "    from urllib import quote_plus\n",
    "    title = dfrow['shorttitle']\n",
    "    year = dfrow['year']\n",
    "    r = requests.get('http://www.omdbapi.com/?t=' + quote_plus(title) + '&y=' +str(year) + '&plot=short&r=json&tomatoes=true')\n",
    "\n",
    "    data = r.json()\n",
    "    newDBrow = pd.io.json.json_normalize(data)\n",
    "    #print(newDBrow)\n",
    "    return newDBrow\n",
    "getJSON(dfsub.iloc[0]).columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now run through the entire ratings list and create a new dataframe with the additional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquired 100\n",
      "\n",
      "Acquired 200\n",
      "\n",
      "Acquired 300\n",
      "\n",
      "Acquired 400\n",
      "\n",
      "Acquired 500\n",
      "\n",
      "Acquired 600\n",
      "\n",
      "Acquired 700\n",
      "\n",
      "Acquired 800\n",
      "\n",
      "Acquired 900\n",
      "\n",
      "Acquired 1000\n",
      "\n",
      "Acquired 1100\n",
      "\n",
      "Acquired 1200\n",
      "\n",
      "Acquired 1300\n",
      "\n",
      "Acquired 1400\n",
      "\n",
      "Acquired 1500\n",
      "\n",
      "Acquired 1600\n",
      "\n",
      "Acquired 1700\n",
      "\n",
      "Acquired 1800\n",
      "\n",
      "Acquired 1900\n",
      "\n",
      "Acquired 2000\n",
      "\n",
      "Acquired 2100\n",
      "\n",
      "Acquired 2200\n",
      "\n",
      "Acquired 2300\n",
      "\n",
      "Acquired 2400\n",
      "\n",
      "Acquired 2500\n",
      "\n",
      "Acquired 2600\n",
      "\n",
      "Acquired 2700\n",
      "\n",
      "Acquired 2800\n",
      "\n",
      "Acquired 2900\n",
      "\n",
      "Acquired 3000\n",
      "\n",
      "Acquired 3100\n",
      "\n",
      "Acquired 3200\n",
      "\n",
      "Acquired 3300\n",
      "\n",
      "Acquired 3400\n",
      "\n",
      "Acquired 3500\n",
      "\n",
      "Acquired 3600\n",
      "\n",
      "Acquired 3700\n",
      "\n",
      "Acquired 3800\n",
      "\n",
      "Acquired 3900\n",
      "\n",
      "Acquired 4000\n",
      "\n",
      "Acquired 4100\n",
      "\n",
      "Acquired 4200\n",
      "\n",
      "Acquired 4300\n",
      "\n",
      "Acquired 4400\n",
      "\n",
      "Acquired 4500\n",
      "\n",
      "Acquired 4600\n",
      "\n",
      "Acquired 4700\n",
      "\n",
      "Acquired 4800\n",
      "\n",
      "Acquired 4900\n",
      "\n",
      "Acquired 5000\n",
      "\n",
      "Acquired 5100\n",
      "\n",
      "Acquired 5200\n",
      "\n",
      "Acquired 5300\n",
      "\n",
      "Acquired 5400\n",
      "\n",
      "Acquired 5500\n",
      "\n",
      "Acquired 5600\n",
      "\n",
      "Acquired 5700\n",
      "\n",
      "Acquired 5800\n",
      "\n",
      "Acquired 5900\n",
      "\n",
      "Acquired 6000\n",
      "\n",
      "Acquired 6100\n",
      "\n",
      "Acquired 6200\n",
      "\n",
      "Acquired 6300\n",
      "\n",
      "Acquired 6400\n",
      "\n",
      "Acquired 6500\n",
      "\n",
      "Acquired 6600\n",
      "\n",
      "Acquired 6700\n",
      "\n",
      "Acquired 6800\n",
      "\n",
      "Acquired 6900\n",
      "\n",
      "Acquired 7000\n",
      "\n",
      "Acquired 7100\n",
      "\n",
      "Acquired 7200\n",
      "\n",
      "Acquired 7300\n",
      "\n",
      "Acquired 7400\n",
      "\n",
      "Acquired 7500\n",
      "\n",
      "Acquired 7600\n",
      "\n",
      "Acquired 7700\n",
      "\n",
      "Acquired 7800\n",
      "\n",
      "Acquired 7900\n",
      "\n",
      "Acquired 8000\n",
      "\n",
      "Acquired 8100\n",
      "\n",
      "Acquired 8200\n",
      "\n",
      "Acquired 8300\n",
      "\n",
      "Acquired 8400\n",
      "\n",
      "Acquired 8500\n",
      "\n",
      "Acquired 8600\n",
      "\n",
      "Acquired 8700\n",
      "\n",
      "Acquired 8800\n",
      "\n",
      "Acquired 8900\n",
      "\n",
      "Acquired 9000\n",
      "\n",
      "Acquired 9100\n",
      "\n",
      "Acquired 9200\n",
      "\n",
      "Acquired 9300\n",
      "\n",
      "Acquired 9400\n",
      "\n",
      "Acquired 9500\n",
      "\n",
      "Acquired 9600\n",
      "\n",
      "Acquired 9700\n",
      "\n",
      "Acquired 9800\n",
      "\n",
      "Acquired 9900\n",
      "\n",
      "Acquired 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nrows = 0\n",
    "newdb = pd.DataFrame()\n",
    "for row,datarow in dfsub.iterrows():\n",
    "    import time\n",
    "    newrow=getJSON(datarow)\n",
    "    if 'Error' not in newrow:\n",
    "        newrow['index'] = row\n",
    "        newrow.set_index('index',inplace=True)\n",
    "        newdb = newdb.append(newrow)\n",
    "        #print(newrow)\n",
    "    nrows += 1\n",
    "    time.sleep(0.1)\n",
    "    if (nrows % 100 == 0):\n",
    "        print('Acquired {}\\n'.format(nrows))\n",
    "newdb.to_csv('../data/openmdb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that this list of movies was too small. I then expanded the list to films with at least 1500 votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10358\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist</th>\n",
       "      <th>votes</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>shorttitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111100001</td>\n",
       "      <td>2543</td>\n",
       "      <td>3.8</td>\n",
       "      <td>#1 Cheerleader Camp (2010) (V)</td>\n",
       "      <td>2010</td>\n",
       "      <td>#1 Cheerleader Camp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2111000000</td>\n",
       "      <td>1594</td>\n",
       "      <td>3.3</td>\n",
       "      <td>#Horror (2015)</td>\n",
       "      <td>2015</td>\n",
       "      <td>#Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0000122100</td>\n",
       "      <td>1693</td>\n",
       "      <td>6.5</td>\n",
       "      <td>$ (1971)</td>\n",
       "      <td>1971</td>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0000122100</td>\n",
       "      <td>2697</td>\n",
       "      <td>6.4</td>\n",
       "      <td>$5 a Day (2008)</td>\n",
       "      <td>2008</td>\n",
       "      <td>$5 a Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0000011113</td>\n",
       "      <td>1936</td>\n",
       "      <td>7.0</td>\n",
       "      <td>$50K and a Call Girl: A Love Story (2014)</td>\n",
       "      <td>2014</td>\n",
       "      <td>$50K and a Call Girl: A Love Story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dist  votes  rating                                      title  \\\n",
       "1   1111100001   2543     3.8             #1 Cheerleader Camp (2010) (V)   \n",
       "24  2111000000   1594     3.3                             #Horror (2015)   \n",
       "57  0000122100   1693     6.5                                   $ (1971)   \n",
       "70  0000122100   2697     6.4                            $5 a Day (2008)   \n",
       "73  0000011113   1936     7.0  $50K and a Call Girl: A Love Story (2014)   \n",
       "\n",
       "    year                          shorttitle  \n",
       "1   2010                 #1 Cheerleader Camp  \n",
       "24  2015                             #Horror  \n",
       "57  1971                                   $  \n",
       "70  2008                            $5 a Day  \n",
       "73  2014  $50K and a Call Girl: A Love Story  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsub2 = df[df['votes']>1500]\n",
    "dfsub2 = dfsub2[dfsub2['votes']<=5000]\n",
    "print(len(dfsub2))\n",
    "dfsub2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I repeat the data acquisition for these additional films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrows = 0\n",
    "newdb2 = pd.DataFrame()\n",
    "for row,datarow in dfsub2.iterrows():\n",
    "    import time\n",
    "    newrow=getJSON(datarow)\n",
    "    if 'Error' not in newrow:\n",
    "        newrow['index'] = row\n",
    "        newrow.set_index('index',inplace=True)\n",
    "        newdb2 = newdb2.append(newrow)\n",
    "        #print(newrow)\n",
    "    nrows += 1\n",
    "    time.sleep(0.1)\n",
    "    if (nrows % 100 == 0):\n",
    "        print('Acquired {}\\n'.format(nrows))\n",
    "newdb2.to_csv('../data/openmdb_more.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condensing Data\n",
    "\n",
    "I now join the datasets together to create a single data file with all of the information I need in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16568\n"
     ]
    }
   ],
   "source": [
    "#Combine the data and look only at the films with more than 1500 votes on IMDb\n",
    "newdb=pd.read_csv('../data/openmdb.csv',encoding='mbcs',index_col=0)\n",
    "newdb2=pd.read_csv('../data/openmdb_more.csv',encoding='mbcs',index_col=0)\n",
    "newdb3 =pd.concat([newdb,newdb2])\n",
    "dfsubmore = df[df['votes']>1500]\n",
    "print(len(newdb3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now join the OpenMDb data with the IMDb data and look at how many rows I still have left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20433\n",
      "16568\n"
     ]
    }
   ],
   "source": [
    "print(len(dfsubmore))\n",
    "dbbig = newdb3.join(dfsubmore)\n",
    "print(len(dbbig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do some feature engineering to create new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def change_text(text):\n",
    "    return text.encode('utf-8')  # assuming the encoding is UTF-8\n",
    "\n",
    "#Get the first director and the list of directors\n",
    "dbbig = dbbig[dbbig['Director'].notnull()]\n",
    "\n",
    "dbbig['Director1']=dbbig['Director'].apply(lambda x: (str(change_text(x)).split(',')[0]))\n",
    "\n",
    "#Create the genre sub listings including 'None' if there are no additional entries\n",
    "dbsub = dbbig['Genre'].apply(lambda x: pd.Series([i for i in reversed(str(x).split(','))]))\n",
    "dbsub.columns = ['Genre1', 'Genre2','Genre3']\n",
    "def getGenre(x):\n",
    "    if pd.notnull(x) and x != 'nan':\n",
    "        return str(x).strip()\n",
    "    else:\n",
    "        return 'None'\n",
    "dbsub['Genre1'] = dbsub['Genre1'].apply(getGenre)\n",
    "dbsub['Genre2'] = dbsub['Genre2'].apply(getGenre)\n",
    "dbsub['Genre3'] = dbsub['Genre3'].apply(getGenre)\n",
    "dbbig = dbbig.join(dbsub)\n",
    "\n",
    "#Create an integer rating that we can predict based on the average value\n",
    "dbbig['stars'] = dbbig['rating'].apply(lambda x: int(np.round(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to randomize the database rows before saving as a `tsv`. This is needed in order to have a random sampling in training the machine learning model on the Amazon Web Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dblearn =dbbig[['title','year','Director1','Genre1','Genre2','Genre3','stars']]\n",
    "dblearn =dblearn.reindex(np.random.permutation(dblearn.index))\n",
    "dblearn.to_csv('../data/movie_ratings_simple.tsv',sep='\\t',index=False,na_rep='None',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also output to a `csv` for futher analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dblearn.to_csv('../data/movie_ratings_simple.csv',sep=',',index=False,na_rep='None',encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
